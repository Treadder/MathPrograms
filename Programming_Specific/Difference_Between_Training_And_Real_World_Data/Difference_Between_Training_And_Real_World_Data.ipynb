{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Developing a way to find the acceptable difference between training and real world data. (MNIST)\n",
    "***\n",
    "\n",
    "*By Jared Kelnhofer, 10-02-2020*\n",
    "\n",
    "This notebook is designed to help me complete my DigitRecognizer program. The problem that I am trying to solve is this: I don't know if the images that I allow the user of my program to draw are close enough to MNIST's to make a good comparison between the two. Just because I provide the user a square to draw in, and resize their created image to 28 by 28 pixels doesn't mean that the end result can actually be compared successfully to the MNIST dataset. My results so far make me think that my generated images might be a little too far off from MNIST. This could require me to change different aspects of my image generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Getting MNIST ready</font>\n",
    "\n",
    "The first order of business is to get the MNIST dataset, and split it into 11 different datasets. I want the MNIST set in full, as well as a set for each digit. The labels are only going to be important for the splitting of the data. Once it's divided up into different CSV files and saved in the /Data directory in this file's directory, we no longer need to bother with labels. Here I grab the dataset, setu up some directories, and get a little info about the shape of MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist keys: dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])\n",
      "Shape of \"data\" key: (70000, 784)\n",
      "Shape of \"target\" key: (70000,)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import os\n",
    "if not os.path.exists('./Dataset'):\n",
    "    os.makedirs('./Dataset')\n",
    "    \n",
    "if not os.path.exists('./Dataset/individual_digits'):\n",
    "    os.makedirs('./Dataset/individual_digits')\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml(\"mnist_784\", version=1, data_home=\"./Dataset\")\n",
    "\n",
    "print(\"Mnist keys: \" + str(mnist.keys()))\n",
    "print(\"Shape of \\\"data\\\" key: \" + str(np.shape(mnist.data)))\n",
    "print(\"Shape of \\\"target\\\" key: \" + str(np.shape(mnist.target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Some helpful Methods</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clear_directory method will be handy as I'm developing, to get rid of extra .csv files. (They can get left behind if I change the amount of files I'm generating, and overwriting.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_directory(folder):\n",
    "    import os, shutil\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll include a TIMESAVER for time saving during development. The higher the TIMESAVER is, the fewer values the get_digit_and_save_to_csv function will iterate over, checking for equality. (Obviously, if you make it 70,000 or more than it will iterate over no values, as MNIST only has 70,000 instances in it.) Also, you can alter the digits_to_get array to include fewer digits for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we're doing: 70000 iterations\n"
     ]
    }
   ],
   "source": [
    "TIMESAVER = 0\n",
    "print(\"we're doing: \" + str(len(mnist.target)-TIMESAVER) + \" iterations\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll write a function *get_digit_and_save_to_csv* that can grab a huge array from MNIST with only instances of a specified digit. Than we'll use this function to split up the dataset in to it's 10 components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_digit_and_save_to_csv(mnist_instance, digit_name):\n",
    "        \n",
    "    filename = \"./Dataset/individual_digits/\" + str(digit_name) + \".csv\" \n",
    "    digit_array = np.empty((0, 784))\n",
    " \n",
    "    for i in range(0, len(mnist_instance.target) - TIMESAVER):\n",
    "        \n",
    "        if(mnist_instance.target[i] == str(digit_name)):\n",
    "            digit_array = np.append(digit_array, mnist_instance.target[i])\n",
    "\n",
    "    np.savetxt(filename, digit_array, delimiter=',', fmt=\"%s\")\n",
    "    return(digit_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_csv_files_by_digit(digits_to_get):\n",
    "    \n",
    "    clear_directory(\"./Dataset/individual_digits\")\n",
    "    \n",
    "    for i in range(0, len(digits_to_get)):\n",
    "        digit_array = get_digit_and_save_to_csv(mnist, digits_to_get[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Generating All our CSV files</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mnist_csv_files_by_digit([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "#create a csv of the whole MNIST dataset called \"all_values\" in the same directory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add up all the values in each of our csv files, it should come to 70000. Let's check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv\n",
    "#count values\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a way to tell how different a value is from another. (For the purposes of this notebook, assume that a value is an MNIST image, 28 by 28 pixels.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
